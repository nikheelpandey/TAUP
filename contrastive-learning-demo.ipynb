{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "import os\n",
    "import time\n",
    "from datetime import datetime \n",
    "from knn_monitor import knn_monitor\n",
    "from model import ContrastiveLearner\n",
    "from data import Loader, cifar_test_transforms, cifar_train_transforms\n",
    "from logger import Logger\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, temp=0.5, normalize= False):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self,xi,xj):\n",
    "\n",
    "        z1 = F.normalize(xi, dim=1)\n",
    "        z2 = F.normalize(xj, dim=1)\n",
    "        \n",
    "        N, Z = z1.shape \n",
    "        device = z1.device \n",
    "        \n",
    "        representations = torch.cat([z1, z2], dim=0)\n",
    "        similarity_matrix = torch.mm(representations, representations.T) / self.temp\n",
    "\n",
    "        # create positive matches\n",
    "        l_pos = torch.diag(similarity_matrix, N)\n",
    "        r_pos = torch.diag(similarity_matrix, -N)\n",
    "        positives = torch.cat([l_pos, r_pos]).view(2 * N, 1)\n",
    "        \n",
    "        # get the values of every pair that's a mismatch\n",
    "        diag = torch.eye(2*N, dtype=torch.bool, device=device)\n",
    "        diag[N:,:N] = diag[:N,N:] = diag[:N,:N]        \n",
    "        negatives = similarity_matrix[~diag].view(2*N, -1)\n",
    "        \n",
    "#         print(positives)\n",
    "#         print(negatives)\n",
    "        \n",
    "        exp_upper = (torch.exp(torch.sum(positives, dim=1)))\n",
    "        exp_lower = (torch.exp((torch.sum(negatives,dim=1))))\n",
    "        \n",
    "        loss = (torch.mean(-torch.log(exp_upper/exp_lower)))\n",
    "        \n",
    "        return loss / (2 * N)\n",
    "\n",
    "# main = torch.rand(4,256)\n",
    "# augm = torch.rand(4,256) \n",
    "# loss = ContrastiveLoss()\n",
    "# loss(main,augm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "\n",
    "def get_backbone(backbone, castrate=True):\n",
    "    if castrate:\n",
    "        backbone.output_dim = backbone.fc.in_features\n",
    "        backbone.fc = torch.nn.Identity()\n",
    "    return backbone\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self,in_shape,out_shape=256):\n",
    "        super().__init__()\n",
    "        hidden_shape = in_shape//2\n",
    "\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Linear(in_shape,hidden_shape),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Linear(hidden_shape,hidden_shape),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer_3 = nn.Linear(hidden_shape,out_shape)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer_1(x)\n",
    "#         x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ContrastiveLearner(nn.Module):\n",
    "    def __init__(self, backbone=resnet50(), projection_head=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = get_backbone(backbone)\n",
    "        self.projection_head = ProjectionHead(backbone.output_dim)\n",
    "        self.loss = ContrastiveLoss(temp=0.5, normalize= True)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.backbone,\n",
    "            self.projection_head\n",
    "        )\n",
    "\n",
    "    def forward(self,x,x_):\n",
    "        \n",
    "        z   = self.encoder(x)\n",
    "\n",
    "        z_  = self.encoder(x_)\n",
    "        loss= self.loss(z,z_)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 'SimCLR'\n",
    "dataset_name = 'CIFAR10C'\n",
    "data_dir = 'dataset'\n",
    "ckpt_dir = \"./ckpt\"\n",
    "features = 128\n",
    "batch = 64\n",
    "epochs = 15\n",
    "lr = 1e-3\n",
    "use_cuda = True\n",
    "device_id = 0\n",
    "wt_decay  = 0.9\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    device = torch.device(\"cuda\")\n",
    "    # torch.cuda.set_device(device_id)\n",
    "    print('GPU')\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Setup tensorboard\n",
    "log_dir = \"./tb\" \n",
    "\n",
    "#create dataset folder \n",
    "if not os.path.exists('dataset'):\n",
    "    os.makedirs('dataset')\n",
    "# Setup asset directories\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "if not os.path.exists('runs'):\n",
    "    os.makedirs('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(log_dir=log_dir, tensorboard=True, matplotlib=True)\n",
    "\n",
    "\n",
    "in_channel = 3\n",
    "train_transform = cifar_train_transforms()\n",
    "test_transform = cifar_test_transforms()\n",
    "target_transform = None\n",
    "\n",
    "\n",
    "loader = Loader(dataset_name, data_dir,True, \n",
    "                batch, train_transform, test_transform,\n",
    "                target_transform, use_cuda)\n",
    "\n",
    "\n",
    "train_loader = loader.train_loader\n",
    "test_loader = loader.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-331b21041715>:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  global_progress = tqdm(range(0, epochs), desc=f'Training')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d971593455c42cca5545e9be2820a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-331b21041715>:12: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "<ipython-input-7-331b21041715>:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  local_progress = tqdm(train_loader, desc=f'Epoch {epoch}/{epochs}')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bea7dae2fba4e24b020788451f7c8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0/15:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'DivBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-331b21041715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# loss =  data_dict['loss'].mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'DivBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "model = ContrastiveLearner().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "            lr=lr,\n",
    "            weight_decay=wt_decay) \n",
    "scheduler = ExponentialLR(optimizer, gamma=wt_decay)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "# start training \n",
    "global_progress = tqdm(range(0, epochs), desc=f'Training')\n",
    "data_dict = {\"loss\": 100}\n",
    "with torch.autograd.detect_anomaly():\n",
    "    for epoch in global_progress:\n",
    "        model.train()   \n",
    "\n",
    "        local_progress = tqdm(train_loader, desc=f'Epoch {epoch}/{epochs}')\n",
    "\n",
    "        for idx, (image, aug_image, label) in enumerate(local_progress):\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss = model.forward(image.to(device, non_blocking=True),aug_image.to(device, non_blocking=True))\n",
    "\n",
    "            # loss =  data_dict['loss'].mean()\n",
    "            data_dict['loss'] = (loss.mean()).item() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            data_dict.update({'lr': scheduler.get_lr()[0]})\n",
    "            local_progress.set_postfix(data_dict)\n",
    "            logger.update_scalers(data_dict)\n",
    "\n",
    "        epoch_dict = {'epoch':epoch, 'accuracy':accuracy}\n",
    "        global_progress.set_postfix(epoch_dict)\n",
    "        logger.update_scalers(epoch_dict)\n",
    "\n",
    "    model_path = os.path.join(ckpt_dir, f\"{uid}_{datetime.now().strftime('%m%d%H%M%S')}.pth\")\n",
    "    torch.save({\n",
    "        'epoch':epoch+1,\n",
    "        'state_dict': model.module.state_dict()\n",
    "            }, model_path)\n",
    "    print(f'Model saved at: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
